---
title: "Report on Matching of Unpaywall and Web of Science"
authors:
  - "Nicholas Fraser"
  - "Anne Hobert"
output:
  html_document:
    keep_md: TRUE
    fig_caption: TRUE
---
## Initial setup

```{r setup, include=FALSE}

# knitr options
knitr::opts_chunk$set(echo = TRUE)

# Call libraries
library(tidyverse)
library(RJDBC)
library(DBI)
library(dbplyr)
library(viridis)

# Download ojdbc8.jar file from Oracle Website, store path to it as rjdbc_path in the environment file .Renviron, store also personal authentication credentials as kb_user01 and kb_password01 there.

# Open DB connection

drv <-JDBC("oracle.jdbc.OracleDriver", classPath= Sys.getenv("rjdbc_path"), " ")
con <- dbConnect(drv, "jdbc:oracle:thin:@//biblio-p-db01:1521/bibliodb01.fiz.karlsruhe", Sys.getenv("kb_user01"), Sys.getenv("kb_password01"))
```

## Motivation

<!-- There is a growing need to monitor open access to scholarly literature. Information on the open access status of research publications is desired to study the development of open availability over time, phenomena connected with open access, like a possible citation advantage, to observe compliance with funder mandates and to inform decision making, be it on institutional level or in science policy.

Yet, gathering information on the open access status often is not a trivial task.-->

This report documents our approach to developing a procedure for the connection of items covered by the Web of Science (WoS) in-house database of the Competence Center for bibliometrics (KB) to information on their open access status contained in the Unpaywall data dump.

<!--mention workshop: fields to be included in the kb version of the dump depend on matching strategy-->

The most straight-forward way to perform a matching between WoS and Unpwaywall is based on [digital object identifiers (doi)](https://www.doi.org/), i.e. persistent interoperable identifiers. However, doi information in WoS is incomplete: not for all records a doi is stored in the database even though many of them are actually included in Unpaywall.

```{r}
#wos_doi_cov <- dbGetQuery(con, read_file("sql/wos_doi_coverage.sql"))
wos_doi_cov_tidy <- wos_doi_cov %>%
  gather("is_null", "number_of_items", -TOTAL_NUMBER_OF_ITEMS, -ARTICLE_TYPE, -PUBYEAR) %>%
  mutate(is_null = case_when(
    is_null == "NUMBER_OF_NULLS" ~ TRUE,
    is_null == "NUMBER_OF_DOIS" ~ FALSE
  )) %>%
  select(-TOTAL_NUMBER_OF_ITEMS)

# Total number of null DOIs per year
wos_doi_cov_tidy %>%
  group_by(PUBYEAR, is_null) %>%
  summarise(number_of_items = sum(number_of_items)) %>%
  ggplot(aes(x = PUBYEAR, y = number_of_items)) + 
    geom_bar(aes(fill = is_null), stat = "identity", position = "dodge") +
    labs(x = "Publication year", y = "Number of items", fill = "DOI is null?",
         title = "What number of items have null-DOI in WoS?")

# Number of null DOIs within articles and reviews per year
wos_doi_cov_tidy %>%
  filter(ARTICLE_TYPE %in% c("article", "review")) %>%
  group_by(PUBYEAR, is_null) %>%
  summarise(number_of_items = sum(number_of_items)) %>%
  ggplot(aes(x = PUBYEAR, y = number_of_items)) + 
    geom_bar(aes(fill = is_null), stat = "identity", position = "dodge") +
    labs(x = "Publication year", y = "Number of articles", fill = "DOI is null?",
         title = "What number of articles and reviews have null-DOI in WoS?")
```
Looking at items in WoS with a publication year between 2012 and 2017, we see that throughout the years, exluding the last one, about `{r} floor(wos_doi_cov_tidy %>% group_by(PUBYEAR, is_null) %>% summarise(number_of_items = sum(number_of_items)) %>% ungroup() %>% filter(is_null == TRUE, PUBYEAR < 2017) %>% summarize(av = mean(number_of_items))/10000) *10000` items do not have any doi information. In the same period, the number of items containing doi information rises continuously from `{r} wos_doi_cov_tidy %>% filter(PUBYEAR == 2012, is_null == FALSE) %>% summarise(number_of_items = sum(number_of_items))` in 2012 to `{r} wos_doi_cov_tidy %>% filter(PUBYEAR == 2016, is_null == FALSE) %>% summarise(number_of_items = sum(number_of_items))` in 2016. The decline in the number of items with and without doi in the last year, 2017, is probably due to an indexing lag. In total, `{r} round(sum(wos_doi_cov_tidy %>% filter(is_null == TRUE) %>% .$number_of_items)/sum(wos_doi_cov_tidy$number_of_items), 4)*100` percent of all items do not have any doi information.

This figure is much smaller if we focus on journal articles an reviews only: Over the whole period from 2012 to 2017, only `{r} round(sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review")) %>% filter(is_null == TRUE) %>% .$number_of_items)/sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review")) %>% .$number_of_items),4 )*100` of all articles indexed in WoS do not have any doi information. Moreover, the absolute number of articles, where the doi is null is declining, as is the proportion of articles without doi. The latter decreases even more strongly, from `{r} round(sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review"), PUBYEAR == 2012) %>% filter(is_null == TRUE) %>% .$number_of_items)/sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review"), PUBYEAR == 2012) %>% .$number_of_items),4 )*100` percent in 2012 to only `{r} round(sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review"), PUBYEAR == 2017) %>% filter(is_null == TRUE) %>% .$number_of_items)/sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review"), PUBYEAR == 2017) %>% .$number_of_items),4 )*100` in 2016.

We now want to investigate more thoroughly how the proportion of items without doi depends on the article type. In order to keep the figures readable, we first identify the most common article types and collate the remaining ones in the category `Other`. Looking at the number of items per article type in the following figures, we decide to keep all types with more than `100,000` items.

```{r}
wos_doi_cov_tidy %>%
  group_by(ARTICLE_TYPE) %>%
  summarise(n = sum(number_of_items)) %>%
  arrange(desc(n)) %>%
  mutate(ARTICLE_TYPE = as_factor(ARTICLE_TYPE)) %>%
  ggplot(aes(ARTICLE_TYPE, n)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    labs(x = "Article type", y = "Number of items", title = "Total number of items per article type")

wos_doi_cov_tidy %>%
  group_by(ARTICLE_TYPE) %>%
  summarise(n = sum(number_of_items)) %>%
  arrange(desc(n)) %>%
  mutate(ARTICLE_TYPE = as_factor(ARTICLE_TYPE)) %>%
  ggplot(aes(ARTICLE_TYPE, n)) +
    geom_bar(stat = "identity") +
    scale_y_log10() +
    coord_flip() +
    labs(x = "Article type", y = "Number of items", title = "Total number of items per article type, logarithmic scale")
```

With this, we see the following behavior for the existence of a doi per article type.

```{r}
# Number of null DOIs per article type
# TODO: maybe make this a relative chart?
wos_doi_cov_tidy_factors <- wos_doi_cov_tidy %>%
  mutate(ARTICLE_TYPE = as_factor(ARTICLE_TYPE))%>%
  group_by(ARTICLE_TYPE) %>%
  summarise(number_of_items = sum(number_of_items)) %>%
  arrange(desc(number_of_items)) %>%
  mutate(article_type_grouped = fct_reorder(fct_relevel(fct_other(ARTICLE_TYPE, keep = ARTICLE_TYPE[.$number_of_items > 0.01*sum(wos_doi_cov_tidy$number_of_items)]), "Other"), number_of_items))
wos_doi_cov_tidy %>%
  mutate(ARTICLE_TYPE = as_factor(ARTICLE_TYPE))%>%
  mutate(article_type_grouped = fct_relevel(fct_other(ARTICLE_TYPE, keep = wos_doi_cov_tidy_factors$article_type_grouped), "Other")) %>%
  group_by(article_type_grouped, is_null) %>%
  summarise(number_of_items = sum(number_of_items)) %>%
  arrange(desc(number_of_items)) %>%
  ggplot(aes(x = fct_relevel(fct_reorder(article_type_grouped, desc(number_of_items)), "Other", after = Inf), y = number_of_items)) + 
    geom_bar(aes(fill = is_null), stat = "identity", position = "dodge") +
    coord_flip() + 
    labs(x = "Publication year", y = "Number of items", fill = "DOI is null?",
         title = "What article types have null-DOI in WoS?")
```
In this figure we see that missing DOIs are an issue particularly for proceedings papers, meeting abstracts, book reviews and marginal categories (`Other`). The proportion of journal articles and reviews without DOI is much lower, as the above results already indicated. However, previous studies have shown that for earlier publication years the DOI coverage is much worse also for these two article types. <!-- insert references or formulate query-->

## Data selection

To develop and test our matching strategy we decided to focus on data from Unpaywall with publication year 2014 to reduce storage space needed (the whole Unpaywall data dump needs more than 100 GB). For the most recent years often indexeing lags cause problems and, as just mentioned, for earlier years the DOI coverage within WoS is much worse. Since the registered publication dates in WoS and Unpaywall sometimes differ (for example, because one takes the online publication date and the other the print publication date), we compared publication years for the entries that could be matched based on DOI. The results are shown in the following figure.

```{r}

# Count total matches as a function of WOS publication year (Unpaywall
# publication year = 2014).

#Gather data
doi_matches_pubyears <- dbGetQuery(con, read_file("sql/doi_matches_publication_years.sql"))

#Display results
doi_matches_pubyears %>%
  ggplot(aes(x=WOS_YEAR, y=MATCHES)) +
  geom_bar(stat="identity") +
  labs(x="WOS Publication Year", y="Number of DOI matched items", title = "How do publication years differ between Unpaywall (2014) and WOS\nfor items matched based on DOIs?") +
  theme_bw()

```

Most items have the same publication year, 2014, in WoS as in the Unpaywall data dump. Some items are associated with one or two years later in WoS than in Unpaywall. A negligible amount of items (`round(doi_matches_pubyears %>% filter(WOS_YEAR %in% c(2012, 2017)) %>% summarise(n = sum(MATCHES))/sum(doi_matches_pubyears$MATCHES), 4)*100` percent of all matched items) is mapped to publication years 2012 or 2017 in WoS. Based on this, we decided to focus try to match items in Unpaywall with items from Wos having the same publication year, or one or two years later.

We further decided to focus exlusively on journal articles and reviews since these are the article types covered best in WoS <!-- insert reference--> and we consider them to be most relevant for the studies and scenarios where our matching strategy might be applied.

This means that from the Unpaywall data we only consider records with publication year 2014 that have the `genre` `journal-article`. We also restrict the data from WoS to items with publication years between 2014 and 2016 and `article type` `article` or `review` in this analysis .

## Data preprocessing

<<<<<<< HEAD
-	How was UPW data prepared (Anne)? -> how did we get data from the UPW data dump into KB?

-	How was data cleaned and normalised for matching (Nick)?
=======
We obtained our set of Unpaywall articles similarly to how it is described in our [blog post on open access evidence in Unpaywall](https://subugoe.github.io/scholcomm_analytics/posts/unpaywall_evidence/). We will outline the main steps again in the following.

First, we downloaded the most recent Unpaywall data dump released in April 2019 from [here](https://s3-us-west-2.amazonaws.com/unpaywall-data-snapshots/) and imported it into a local MongoDB database. The snapshot contains more than 100 million records and hence, the file is about 100 GB large. To obtain a more manageable object to work with, we extracted the fields which are most relevant to our matching objective using the following query:

```{bash}
"C:\Program Files\MongoDB\Server\4.0\bin\mongo.exe"
db.unpaywallApr19.aggregate([
   {
      $match: {
          year: { $gte: 2014, $lte: 2016}
      }
   },
   {
      $project: {
          doi: 1,
          year: 1,
          genre: 1,
          title: 1,
          AuthorCount: { $cond: { if: { $isArray: "$z_authors" }, then: { $size: "$z_authors" }, else: null} },
          AuthorFirst: { $cond: { if: { $isArray: "$z_authors" }, then: { $arrayElemAt: [ "$z_authors", 0 ] }, else: null } },
          AuthorLast: { $cond: { if: { $isArray: "$z_authors" }, then: { $arrayElemAt: [ "$z_authors", -1 ] }, else: null } }
      }
   },
   {
      $out: 'authorInformation' 
   }
] )
```

Note that on a Linux or Mac OS, single quotes (`'`) and double quotes (`"`) need to be exchanged. We filtered for publication years between 2014 and 2016, extracted doi, publication year, article type (`genre`), article title, and some author information, namely the number of authors, and the given and family names of the first and last author. For single author articles, the first and last author coincide. We exported the resulting data as json file and loaded it as table into our [GoogleBigQuery](https://cloud.google.com/bigquery/) analytical environment (paid service, access protected), specifying a [schema](schema_bigquery.json). There, we added information on the journal (ISSN and journal title) to the data from a previous export based on the local MongoDB database. We joined the journal related fields on DOI, which was possible since every Unpaywall entry contains DOI information. We then exported the table as three different .csv files, one for each publication year and imported them into the oracle environment of the KB.

<!-- -	How was data cleaned and normalised for matching (Nick)?-->
>>>>>>> 863b9667a6c03f26b19ec1b6dd114e6b1b766880

For matching of fields between WoS and Unpaywall, it is necessary to standardise (or normalise) and clean data.

The following steps were taken:

- DOI (WoS and Unpaywall): Remove leading or trailing whitespace (Oracle 'TRIM' function), set to lowercase (Oracle 'LOWER' function)
- Article title: Remove leading or trailing whitespace, set to lowercase
- Journal name
- Author names?



## Matching criteria

<<<<<<< HEAD
-	What potential criteria could we match on?

In this report we focus on a subset of criteria which may potentially be used to match WoS and Unpaywall records. Namely, we focus on DOIs, article titles, journal titles and ISSNs, and authorship information including author counts and names. We note that these criteria are not exhaustive, for example volume or issue number, however these criteria



=======
<!--(Nick)
-	What potential criteria could we match on? 
>>>>>>> 863b9667a6c03f26b19ec1b6dd114e6b1b766880
-	What is the matching potential of each criteria? Systematic analysis of matching potential (using DOI-matches) â€“ e.g. which publication years do articles usually match on, what percentage can be matched with exact author counts, etc.
-	Other filters that have to be considered (e.g. title blacklists)-->

## Matching algorithm

<!--(Anne/Nick)
Description of algorithm-->

The first step of our matching routine is simply using DOIs where they exist and are present in both databases. The more interesting part is the matching of articles without DOI information based on the criteria discussed in the previous section. As mentioned before, we only consider `journal article`s from Unpaywall and `articles`s and `review`s from WoS. We only try to match articles where the publication year from WoS is the same as or up to two years after the one in Unpaywall. Since all Unpaywall articles we investigated in this analysis are from 2014, we perform the matching on WoS articles with publication year between 2014 and 2016.

Both datasets contain titles which occur in multiple rows. We decided to exclude all of these titles from our matching candidates since we want to think of an article's title as unique for this publication. We therefore created tables listing such titles using [these queries](create_title_blacklists.sql) to later exclude the corresponding entries from the matching. We also exluded all titles starting with one of the keywords contain in [this list](title_keyword_blacklist.csv), e.g. "correction", "erratum", or "addendum" since they would otherwise wrongly be matched with the original articles. <!-- maybe make this a preprocessing step? Might also reduce runtime of the matching algorithm!-->

Since the comparison of titles to determine their similarity measure is costly, we try to narrow down the subset of possible matching candidates as far as possible using the following criteria:

- pubyear: As mentioned, before we require the publication year in WoS to be the same as or up to two years after the Unpaywall publication year.
- journal information: We restrict matching candidates to records with the same ISSN or (exactly) the same journal title. When multiple ISSNs are associated with an article (e.g. of the print and electronic version of the journal), we compare to all of them.
- author count: We compare only articles with coinciding number of authors.

Then, we classify as matched articles the ones which have a title similarity (edit distance) of more than 80 percent.

This results in the query stored as [create_upw14_wos_matching_results_3.sql](create_upw14_wos_matching_results_3.sql) to obtain a list of matchings.

## Results

...
