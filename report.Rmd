---
title: "Report on Matching of Unpaywall and Web of Science"
authors:
  - "Nicholas Fraser"
  - "Anne Hobert"
output:
  html_document:
    keep_md: TRUE
    fig_caption: TRUE
---
## Initial setup

```{r setup, include=FALSE}

# knitr options
knitr::opts_chunk$set(echo = TRUE)

# Call libraries
library(tidyverse)
library(RJDBC)
library(DBI)
library(dbplyr)
library(viridis)

# Download ojdbc8.jar file from Oracle Website, store path to it as rjdbc_path in the environment file .Renviron, store also personal authentication credentials as kb_user01 and kb_password01 there.

# Open DB connection

drv <-JDBC("oracle.jdbc.OracleDriver", classPath= Sys.getenv("rjdbc_path"), " ")
con <- dbConnect(drv, "jdbc:oracle:thin:@//biblio-p-db01:1521/bibliodb01.fiz.karlsruhe", Sys.getenv("kb_user01"), Sys.getenv("kb_password01"))
```

## Motivation

<!-- There is a growing need to monitor open access to scholarly literature. Information on the open access status of research publications is desired to study the development of open availability over time, phenomena connected with open access, like a possible citation advantage, to observe compliance with funder mandates and to inform decision making, be it on institutional level or in science policy.

Yet, gathering information on the open access status often is not a trivial task.-->

This report documents our approach to developing a procedure for the connection of items covered by the Web of Science (WoS) in-house database of the Competence Center for bibliometrics (KB) to information on their open access status contained in the Unpaywall data dump.

<!--mention workshop: fields to be included in the kb version of the dump depend on matching strategy-->

The most straight-forward way to perform a matching between WoS and Unpwaywall is based on [digital object identifiers (doi)](https://www.doi.org/), i.e. persistent interoperable identifiers. However, doi information in WoS is incomplete: not for all records a doi is stored in the database even though many of them are actually included in Unpaywall.

```{r}
#wos_doi_cov <- dbGetQuery(con, read_file("sql/wos_doi_coverage.sql"))
wos_doi_cov_tidy <- wos_doi_cov %>%
  gather("is_null", "number_of_items", -TOTAL_NUMBER_OF_ITEMS, -ARTICLE_TYPE, -PUBYEAR) %>%
  mutate(is_null = case_when(
    is_null == "NUMBER_OF_NULLS" ~ TRUE,
    is_null == "NUMBER_OF_DOIS" ~ FALSE
  )) %>%
  select(-TOTAL_NUMBER_OF_ITEMS)

# Total number of null DOIs per year
wos_doi_cov_tidy %>%
  group_by(PUBYEAR, is_null) %>%
  summarise(number_of_items = sum(number_of_items)) %>%
  ggplot(aes(x = PUBYEAR, y = number_of_items)) + 
    geom_bar(aes(fill = is_null), stat = "identity", position = "dodge") +
    labs(x = "Publication year", y = "Number of items", fill = "DOI is null?",
         title = "What number of items have null-DOI in WoS?")

# Number of null DOIs within articles and reviews per year
wos_doi_cov_tidy %>%
  filter(ARTICLE_TYPE %in% c("article", "review")) %>%
  group_by(PUBYEAR, is_null) %>%
  summarise(number_of_items = sum(number_of_items)) %>%
  ggplot(aes(x = PUBYEAR, y = number_of_items)) + 
    geom_bar(aes(fill = is_null), stat = "identity", position = "dodge") +
    labs(x = "Publication year", y = "Number of articles", fill = "DOI is null?",
         title = "What number of articles and reviews have null-DOI in WoS?")
```
Looking at items in WoS with a publication year between 2012 and 2017, we see that throughout the years, exluding the last one, about `{r} floor(wos_doi_cov_tidy %>% group_by(PUBYEAR, is_null) %>% summarise(number_of_items = sum(number_of_items)) %>% ungroup() %>% filter(is_null == TRUE, PUBYEAR < 2017) %>% summarize(av = mean(number_of_items))/10000) *10000` items do not have any doi information. In the same period, the number of items containing doi information rises continuously from `{r} wos_doi_cov_tidy %>% filter(PUBYEAR == 2012, is_null == FALSE) %>% summarise(number_of_items = sum(number_of_items))` in 2012 to `{r} wos_doi_cov_tidy %>% filter(PUBYEAR == 2016, is_null == FALSE) %>% summarise(number_of_items = sum(number_of_items))` in 2016. The decline in the number of items with and without doi in the last year, 2017, is probably due to an indexing lag. In total, `{r} round(sum(wos_doi_cov_tidy %>% filter(is_null == TRUE) %>% .$number_of_items)/sum(wos_doi_cov_tidy$number_of_items), 4)*100` percent of all items do not have any doi information.

This figure is much smaller if we focus on journal articles an reviews only: Over the whole period from 2012 to 2017, only `{r} round(sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review")) %>% filter(is_null == TRUE) %>% .$number_of_items)/sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review")) %>% .$number_of_items),4 )*100` of all articles indexed in WoS do not have any doi information. Moreover, the absolute number of articles, where the doi is null is declining, as is the proportion of articles without doi. The latter decreases even more strongly, from `{r} round(sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review"), PUBYEAR == 2012) %>% filter(is_null == TRUE) %>% .$number_of_items)/sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review"), PUBYEAR == 2012) %>% .$number_of_items),4 )*100` percent in 2012 to only `{r} round(sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review"), PUBYEAR == 2017) %>% filter(is_null == TRUE) %>% .$number_of_items)/sum(wos_doi_cov_tidy %>% filter(ARTICLE_TYPE %in% c("article", "review"), PUBYEAR == 2017) %>% .$number_of_items),4 )*100` in 2016.

We now want to investigate more thoroughly how the proportion of items without doi depends on the article type. In order to keep the figures readable, we first identify the most common article types and collate the remaining ones in the category `Other`. Looking at the number of items per article type in the following figures, we decide to keep all types with more than `100,000` items.

```{r}
wos_doi_cov_tidy %>%
  group_by(ARTICLE_TYPE) %>%
  summarise(n = sum(number_of_items)) %>%
  arrange(desc(n)) %>%
  mutate(ARTICLE_TYPE = as_factor(ARTICLE_TYPE)) %>%
  ggplot(aes(ARTICLE_TYPE, n)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    labs(x = "Article type", y = "Number of items", title = "Total number of items per article type")

wos_doi_cov_tidy %>%
  group_by(ARTICLE_TYPE) %>%
  summarise(n = sum(number_of_items)) %>%
  arrange(desc(n)) %>%
  mutate(ARTICLE_TYPE = as_factor(ARTICLE_TYPE)) %>%
  ggplot(aes(ARTICLE_TYPE, n)) +
    geom_bar(stat = "identity") +
    scale_y_log10() +
    coord_flip() +
    labs(x = "Article type", y = "Number of items", title = "Total number of items per article type, logarithmic scale")
```

With this, we see the following behavior for the existence of a doi per article type.

```{r}
# Number of null DOIs per article type
# TODO: maybe make this a relative chart?
wos_doi_cov_tidy_factors <- wos_doi_cov_tidy %>%
  mutate(ARTICLE_TYPE = as_factor(ARTICLE_TYPE))%>%
  group_by(ARTICLE_TYPE) %>%
  summarise(number_of_items = sum(number_of_items)) %>%
  arrange(desc(number_of_items)) %>%
  mutate(article_type_grouped = fct_reorder(fct_relevel(fct_other(ARTICLE_TYPE, keep = ARTICLE_TYPE[.$number_of_items > 0.01*sum(wos_doi_cov_tidy$number_of_items)]), "Other"), number_of_items))
wos_doi_cov_tidy %>%
  mutate(ARTICLE_TYPE = as_factor(ARTICLE_TYPE))%>%
  mutate(article_type_grouped = fct_relevel(fct_other(ARTICLE_TYPE, keep = wos_doi_cov_tidy_factors$article_type_grouped), "Other")) %>%
  group_by(article_type_grouped, is_null) %>%
  summarise(number_of_items = sum(number_of_items)) %>%
  arrange(desc(number_of_items)) %>%
  ggplot(aes(x = fct_reorder(article_type_grouped, desc(number_of_items)), y = number_of_items)) + 
    geom_bar(aes(fill = is_null), stat = "identity", position = "dodge") +
    coord_flip() + 
    labs(x = "Publication year", y = "Number of itmes", fill = "DOI is null?",
         title = "What article types have null-DOI in WoS?")
```


## Data selection

-	Which data will we use to test new matching methods? -> UPW data from 2014, WOS data from 2012-2017.
-	Focus on journal articles

## Data preprocessing

-	How was UPW data prepared (Anne)? -> how did we get data from the UPW data dump into KB?
-	How was data cleaned and normalised for matching (Nick)?

## Matching criteria

-	What potential criteria could we match on? 
-	What is the matching potential of each criteria? Systematic analysis of matching potential (using DOI-matches) â€“ e.g. which publication years do articles usually match on, what percentage can be matched with exact author counts, etc.
-	Other filters that have to be considered (e.g. title blacklists)

## Matching algorithm

Description of algorithm

## Results

...
